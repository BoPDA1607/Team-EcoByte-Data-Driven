{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "E4eprmtcqBrv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4eprmtcqBrv",
        "outputId": "9aee7a79-5f59-4b70-c049-7710f5679f24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nO-JYu4qqUlg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nO-JYu4qqUlg",
        "outputId": "0393f5f8-2de2-41a4-9740-d6a3331f13ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.3-cp310-cp310-manylinux2014_x86_64.whl (98.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.3\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n",
            "Collecting dask_ml\n",
            "  Downloading dask_ml-2024.3.20-py3-none-any.whl (148 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.9/148.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dask[array,dataframe]>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from dask_ml) (2023.8.1)\n",
            "Requirement already satisfied: distributed>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from dask_ml) (2023.8.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from dask_ml) (0.58.1)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from dask_ml) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from dask_ml) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask_ml) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from dask_ml) (1.11.4)\n",
            "Collecting dask-glm>=0.2.0 (from dask_ml)\n",
            "  Downloading dask_glm-0.3.2-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: multipledispatch>=0.4.9 in /usr/local/lib/python3.10/dist-packages (from dask_ml) (1.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from dask_ml) (24.0)\n",
            "Requirement already satisfied: cloudpickle>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from dask-glm>=0.2.0->dask_ml) (2.2.1)\n",
            "Collecting sparse>=0.7.0 (from dask-glm>=0.2.0->dask_ml)\n",
            "  Downloading sparse-0.15.1-py2.py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (8.1.7)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (2023.6.0)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (1.4.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (6.0.1)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (7.1.0)\n",
            "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask_ml) (3.1.3)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask_ml) (1.0.0)\n",
            "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask_ml) (1.0.8)\n",
            "Requirement already satisfied: psutil>=5.7.2 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask_ml) (5.9.5)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask_ml) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask_ml) (3.0.0)\n",
            "Requirement already satisfied: tornado>=6.0.4 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask_ml) (6.3.3)\n",
            "Requirement already satisfied: urllib3>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask_ml) (2.0.7)\n",
            "Requirement already satisfied: zict>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask_ml) (3.0.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->dask_ml) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->dask_ml) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->dask_ml) (2023.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->dask_ml) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->dask_ml) (3.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask[array,dataframe]>=2.4.0->dask_ml) (3.18.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.10.3->distributed>=2.4.0->dask_ml) (2.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.24.2->dask_ml) (1.16.0)\n",
            "Installing collected packages: sparse, dask-glm, dask_ml\n",
            "Successfully installed dask-glm-0.3.2 dask_ml-2024.3.20 sparse-0.15.1\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost\n",
        "!pip install scikit-learn\n",
        "!pip install dask_ml"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad7256a6-d40d-4fce-9e5a-bd2a2a366f60",
      "metadata": {
        "id": "ad7256a6-d40d-4fce-9e5a-bd2a2a366f60"
      },
      "source": [
        "### **1. IMPORT LIBRARY**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7d45eb1-5ead-49d9-89b9-077a59f55198",
      "metadata": {
        "id": "d7d45eb1-5ead-49d9-89b9-077a59f55198"
      },
      "outputs": [],
      "source": [
        "# Third-party library imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import dask.dataframe as dd\n",
        "from dask_ml.model_selection import train_test_split\n",
        "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
        "from statistics import mean\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Third-party library models imports\n",
        "from catboost import CatBoostRegressor\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgbm\n",
        "from sklearn.linear_model import Ridge"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bf1cbfd-3789-4048-b813-963f03ccf8ee",
      "metadata": {
        "id": "8bf1cbfd-3789-4048-b813-963f03ccf8ee"
      },
      "source": [
        "### **2. ACQUIRE DATA**\n",
        "- **Note**: D:\\Team EcoByte Data-Driven\\ to your directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "apgHcetWv1bC",
      "metadata": {
        "id": "apgHcetWv1bC"
      },
      "outputs": [],
      "source": [
        "file_path = r\"/content/drive/MyDrive/Data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xXtrY2Davd3p",
      "metadata": {
        "id": "xXtrY2Davd3p"
      },
      "outputs": [],
      "source": [
        "data = dd.read_csv(file_path + 'ProcessedData.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UVGxQ4t4TajS",
      "metadata": {
        "id": "UVGxQ4t4TajS"
      },
      "outputs": [],
      "source": [
        "f = open(file_path + 'Accuracy.txt', \"a\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YOA9fzNAURXj",
      "metadata": {
        "id": "YOA9fzNAURXj"
      },
      "outputs": [],
      "source": [
        "test_case = \"Test_run_101\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. CLASS**"
      ],
      "metadata": {
        "id": "z_sGFqluxEIw"
      },
      "id": "z_sGFqluxEIw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ZmR9ngvy5M6",
      "metadata": {
        "id": "7ZmR9ngvy5M6"
      },
      "outputs": [],
      "source": [
        "class EarlyStoppingRegressor(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, estimator, early_stopping_rounds=2, train_size = 0, sample_size = 500000, **kwargs):\n",
        "        self.estimator = estimator\n",
        "        self.early_stopping_rounds = early_stopping_rounds\n",
        "        self.estimators_ = []\n",
        "        self.score = []\n",
        "        self.train_size = train_size\n",
        "        self.sample_size = sample_size\n",
        "    def fit(self, X, y, X_val, y_val):\n",
        "        self.estimators_ = []\n",
        "        best_score = float(\"inf\")\n",
        "        early_stopping_count = 0\n",
        "        for i in range(0, self.train_size, self.sample_size):\n",
        "          X_sample, y_sample = split_sample_size(X, y, i, self.sample_size)\n",
        "          for i in range(3):\n",
        "            estimator = clone(self.estimator)\n",
        "            estimator.fit(X_sample, y_sample)\n",
        "            self.estimators_.append(estimator)\n",
        "            val_error = estimator.score(X_val, y_val)\n",
        "            if val_error < best_score:\n",
        "                best_score = val_error\n",
        "                early_stopping_count = 0\n",
        "            else:\n",
        "                early_stopping_count += 1\n",
        "            if early_stopping_count >= self.early_stopping_rounds:\n",
        "                break\n",
        "        return self\n",
        "    def predict(self, X):\n",
        "        return self.estimators_[-1].predict(X)\n",
        "    def get_feature_importance(self, model):\n",
        "      if model == 'linear':\n",
        "        return self.estimators_[-1].coef_[0].round(2)\n",
        "      else:\n",
        "        if(sum(pipeline[1].feature_importances_.round(2)) != 1):\n",
        "          return (self.estimators_[-1].feature_importances_.round(2)/sum(self.estimators_[-1].feature_importances_.round(2)).round(2)).round(2)\n",
        "        else:\n",
        "          return self.estimators_[-1].feature_importances_.round(2)\n",
        "    def get_features(self, model):\n",
        "      if model == 'linear':\n",
        "        return self.estimators_[-1].feature_names_in_\n",
        "      else:\n",
        "        return self.estimators_[-1].feature_names_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RNvbUtJ5uxRR",
      "metadata": {
        "id": "RNvbUtJ5uxRR"
      },
      "source": [
        "### **3. FUNCTION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bwYI1qQivBnU",
      "metadata": {
        "id": "bwYI1qQivBnU"
      },
      "outputs": [],
      "source": [
        "def split_sample_size(X_train, y_train, i, batch_size):\n",
        "  X_batch = X_train[i:i+batch_size]\n",
        "  y_batch = y_train[i:i+batch_size]\n",
        "  return X_batch, y_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "358033c8-2ac3-4167-93b8-f9c357e7ac67",
      "metadata": {
        "id": "358033c8-2ac3-4167-93b8-f9c357e7ac67"
      },
      "source": [
        "### **4. MACHINE LEARNING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e735a1ff-da5c-4080-b631-24f5f9055f50",
      "metadata": {
        "id": "e735a1ff-da5c-4080-b631-24f5f9055f50"
      },
      "outputs": [],
      "source": [
        "features_importance = ['AGE', 'TENURE_IN_DAYS', 'FOB_RACING_TURNOVER', 'FOB_SPORT_TURNOVER', 'PARI_RACING_TURNOVER',\n",
        "                  'PARI_SPORT_TURNOVER', 'DIVIDENDS_PAID', 'TICKETS', 'IS_WEEKEND', 'IS_WEEKDAY',\n",
        "                  'IS_YEAR', 'IS_MONTH', 'SEASON_ENCODE', 'MALE', 'FEMALE', 'UNKNOWN', 'GENDER_AGE_BAND', 'IS_HOLIDAY',\n",
        "                  'IS_WA', 'IS_OTH', 'IS_YEAR_2021', 'IS_YEAR_2022', 'CUSTOMER_STATUS', 'GROSS_MARGIN_STATUS',\n",
        "                  'IS_PLAY_FOB_RACING', 'IS_PLAY_FOB', 'IS_PLAY_PARI_RACING', 'IS_WORLD_CUP', 'IS_BET_DURING_WORLD_CUP', 'AGE_BAND',\n",
        "                  \"SEGMENT_DAY_OF_WEEK\", 'IS_SPRING', 'IS_SUMMER', 'IS_AUTUMN', 'IS_WINTER', 'IS_PLAY_SPORT', 'IS_PLAY_RACING' , 'IS_PLAY_BET',\n",
        "                  'IS_PLAY_PARI_SPORT', 'IS_PLAY_PARI', 'IS_PLAY_FOB_SPORT', 'DAY_OF_WEEK', 'SEGMENT_GENDER_DAY_OF_WEEK_RESIDENTIAL',\n",
        "                  'Segment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4116f0ab-1424-4d52-86c5-8de29bdaf928",
      "metadata": {
        "id": "4116f0ab-1424-4d52-86c5-8de29bdaf928"
      },
      "outputs": [],
      "source": [
        "target_feature = ['TOTAL_TURNOVER']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d36b43e-88d1-4ac5-adf8-e69db414ea9b",
      "metadata": {
        "id": "5d36b43e-88d1-4ac5-adf8-e69db414ea9b"
      },
      "source": [
        "#### **STEP 1: SEPARATE IMPORTANT FEATURES AND TARGET LABEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6192617b-b28c-4d59-addc-8630abba97e1",
      "metadata": {
        "id": "6192617b-b28c-4d59-addc-8630abba97e1"
      },
      "outputs": [],
      "source": [
        "X = data[features_importance]\n",
        "y = data[target_feature]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffcbd417-e1b4-4869-9acc-5cc0ff9260f1",
      "metadata": {
        "id": "ffcbd417-e1b4-4869-9acc-5cc0ff9260f1"
      },
      "source": [
        "#### **STEP 2: SPLIT DATA INTO TRAIN, VALIDATION AND TEST SETS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc63c644-74dd-49fa-b722-f917114e0929",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc63c644-74dd-49fa-b722-f917114e0929",
        "outputId": "7f7cae77-9cb1-45af-94ce-9a6103829318"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask_ml/model_selection/_split.py:465: FutureWarning: The default value for 'shuffle' must be specified when splitting DataFrames. In the future DataFrames will automatically be shuffled within blocks prior to splitting. Specify 'shuffle=True' to adopt the future behavior now, or 'shuffle=False' to retain the previous behavior.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1607)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qzzdDVFfxO-S",
      "metadata": {
        "id": "qzzdDVFfxO-S"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1607)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "H_7FDEOFfj3K",
      "metadata": {
        "id": "H_7FDEOFfj3K"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.compute()\n",
        "y_train = y_train.compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BG7kL5-q2ipc",
      "metadata": {
        "id": "BG7kL5-q2ipc"
      },
      "outputs": [],
      "source": [
        "sample_size = 500000\n",
        "train_size = len(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a0dfb0b-f368-42a5-a2e0-42ae1e18d7d8",
      "metadata": {
        "id": "6a0dfb0b-f368-42a5-a2e0-42ae1e18d7d8"
      },
      "source": [
        "#### **STEP 3: DEFINE PIPELINE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaeSeK0Y7P24",
      "metadata": {
        "id": "eaeSeK0Y7P24"
      },
      "outputs": [],
      "source": [
        "pipelines = [\n",
        "    ('linear', EarlyStoppingRegressor(Ridge(alpha=0.1), train_size = train_size, sample_size = sample_size)),\n",
        "    # ('lightgbm', EarlyStoppingRegressor(lgbm.LGBMRegressor(n_estimators = 100, learning_rate = 0.01, verbose=-1, objective='regression', metric='rmse', lambda_l2=0.1), train_size = train_size, sample_size = sample_size)),\n",
        "    # ('xgboost', EarlyStoppingRegressor(xgb.XGBRegressor(n_estimators = 100, learning_rate = 0.01, verbosity=0, objective='reg:squarederror', reg_lambda=0.1),  train_size = train_size, sample_size = sample_size)),\n",
        "    # ('catboost', EarlyStoppingRegressor(CatBoostRegressor(n_estimators=100, learning_rate = 0.01, verbose=False, l2_leaf_reg=3),  train_size = train_size, sample_size = sample_size))\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62086f8e-1e23-4639-9fbb-6ed60d23de21",
      "metadata": {
        "id": "62086f8e-1e23-4639-9fbb-6ed60d23de21"
      },
      "source": [
        "#### **STEP 4: TRAIN AND EVALUATE EACH MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Hj9konEn133B",
      "metadata": {
        "id": "Hj9konEn133B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5db42f3c-4a7e-421a-e4b6-a6a9bbc41e2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training linear...\n"
          ]
        }
      ],
      "source": [
        "for name, pipeline in pipelines:\n",
        "    print(f\"Training {name}...\")\n",
        "    pipeline.fit(X_train, y_train, X_val.compute(), y_val.compute())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f.write(f\"{test_case}\" + '\\n')\n",
        "for name, pipeline in pipelines:\n",
        "  score_batch = []\n",
        "  for i in range(0, train_size, sample_size):\n",
        "    X_batch, y_batch = split_sample_size(X_train, y_train, i, sample_size)\n",
        "    score_batch.append(r2_score(y_batch, pipeline.predict(X_batch)))\n",
        "  score_train = mean(score_batch)\n",
        "  score_val = r2_score(y_val.compute(), pipeline.predict(X_val.compute()))\n",
        "  score_test = r2_score(y_test.compute(), pipeline.predict(X_test.compute()))\n",
        "  f.write(f\"- {name} accuracy on train: {score_train:.2}\\n\")\n",
        "  f.write(f\"- {name} accuracy on validation: {score_val:.2}\\n\")\n",
        "  f.write(f\"- {name} accuracy on test: {score_test:.2}\\n\")\n",
        "f.write('------------------------------------\\n')\n",
        "f.close()"
      ],
      "metadata": {
        "id": "5RzGV74bqFIc"
      },
      "id": "5RzGV74bqFIc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "22e6f229-c734-4510-9f0d-c725c87758c9",
      "metadata": {
        "id": "22e6f229-c734-4510-9f0d-c725c87758c9"
      },
      "source": [
        "#### **STEP 5: AQUIRE FEATURE IMPORTANCES**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance_df = pd.DataFrame(pipelines[0][1].get_features(pipelines[0][0]))"
      ],
      "metadata": {
        "id": "MpYLte58GTR2"
      },
      "id": "MpYLte58GTR2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZCBIVXYkDMPk",
      "metadata": {
        "id": "ZCBIVXYkDMPk"
      },
      "outputs": [],
      "source": [
        "for name, pipeline in pipelines:\n",
        "  feature_importance_df[name] = pipeline.get_feature_importance(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "X9_Db2FWycrR",
      "metadata": {
        "id": "X9_Db2FWycrR"
      },
      "outputs": [],
      "source": [
        "feature_importance_df.rename(columns={0 : 'Features'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bPCSUdqSaKY9",
      "metadata": {
        "id": "bPCSUdqSaKY9"
      },
      "outputs": [],
      "source": [
        "feature_importance_df.to_csv(file_path + f'{test_case}.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhGIttYZG5RG"
      },
      "source": [
        "#### **STEP 6: CALCULATE P-VALUES**"
      ],
      "id": "JhGIttYZG5RG"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vrhr9VtZVjdj"
      },
      "id": "vrhr9VtZVjdj",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}